services:

  zookeeper:
    image: bitnami/zookeeper:latest  # ARM-compatible image
    container_name: ktech_zookeeper
    platform: linux/arm64
    ports:
      - "2181:2181"
    # restart: unless-stopped
    networks:
      - bridge
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes  # Required for Bitnami images

  kafka:
    image: bitnami/kafka:latest
    container_name: ktech_kafka
    ports:
      - "9094:9094"  # External Kafka port
    expose:
      - "9092"        # Internal Kafka port
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_CREATE_TOPICS=stock-general-information:4:1,real-time-stock-prices:4:1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    # restart: unless-stopped
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9092"]
      interval: 10s
      timeout: 5s
      retries: 5  
    networks:
      - bridge

  spark-master:
    image: bitnami/spark:latest
    platform: linux/arm64
    container_name: ktech_spark 
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - "8080:8080"  # Spark Web UI
      - "7077:7077"
    depends_on:
      - kafka  # Ensure Kafka is up before starting Spark
    volumes:
      - ./:/app/ # Mount your Spark Streaming app
    # restart: unless-stopped
    networks:
      - bridge

  spark-submit:
    image: bitnami/spark:latest
    platform: linux/arm64
    container_name: ktech_spark_submit
    environment:
      - INFLUXDB_BUCKET=${INFLUXDB_BUCKET}
      - INFLUXDB_MEASUREMENT=${INFLUXDB_MEASUREMENT}
      - INFLUX_ORG=${INFLUX_ORG}
      - INFLUX_TOKEN=VKR22D-WaOBEH_LcTksCB7w-FUVFd5YdCpkP2tnYdCByQeimu1SFZ72ZhlMlGqXzDMtFThiBkc1GbBewrMGPTQ==
    volumes:
      - ./:/app/
      - ./packages/postgresql-42.5.4.jar:/opt/bitnami/spark/jars/postgresql-42.5.4.jar
    command: >
      sh -c "pip install --no-cache-dir -r /app/requirements.txt && spark-submit --jars /opt/bitnami/spark/jars/postgresql-42.5.4.jar --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.3 --master spark://spark-master:7077 /app/consumer/consumer.py"
    depends_on:
      - spark-master
    # restart: unless-stopped
    networks:
      - bridge


  spark-worker:
    image: bitnami/spark:latest
    platform: linux/arm64
    container_name: ktech_spark_worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    # restart: unless-stopped
    networks:
      - bridge

  postgresql:
    image: postgres:latest
    container_name: ktech_postgresql
    environment:
      - POSTGRES_DB=stock-info
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - ./script/initdb.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - bridge

  influxdb:
    image: bitnami/influxdb:latest
    platform: linux/arm64
    container_name: influxdb
    # restart: always
    ports:
      - "8086:8086"
    volumes:
      - ./influxdb:/bitnami/influxdb 
    environment:
    - INFLUXDB_ADMIN_USER=admin
    - INFLUXDB_ADMIN_USER_PASSWORD=admin@123
    - INFLUXDB_USER=admin
    - INFLUXDB_USER_PASSWORD=admin@123
    - INFLUX_TOKEN=VKR22D-WaOBEH_LcTksCB7w-FUVFd5YdCpkP2tnYdCByQeimu1SFZ72ZhlMlGqXzDMtFThiBkc1GbBewrMGPTQ==
    depends_on:
      - postgresql
    networks:
      - bridge
  

  grafana:
    image: grafana/grafana-oss:8.4.3
    container_name: grafana
    volumes:
      - grafana-storage:/var/lib/grafana  # Correctly mount the volume
    depends_on:
      - influxdb
    ports:
      - "3000:3000"
    networks:
      - bridge


  stock-python:
    image: stock-python
    container_name: stock-python
    build: ./producer
    ports:
      - "5001:5000"
    depends_on:
      - postgresql
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DBNAME=${POSTGRES_DBNAME}
      - STOCKS=${STOCKS}
    volumes:
      - ./logs:/app/logs
      - ./script:/app/script
    networks:
      - bridge

volumes:
  grafana-storage:
    driver: local

networks:
  bridge: